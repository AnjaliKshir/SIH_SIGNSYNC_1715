<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Speech to Text with Animation</title>
    <link rel="stylesheet" href="static/style.css" />
    <style>
      #animation_container {
        position: relative;
        width: 100%;
        max-width: 600px;
        margin: 0 auto;
      }

      #avatarImage {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        object-fit: contain;
        display: block;
      }

      #wordAnimation {
        width: 100%;
        height: 100%;
        display: none;
      }

      .output-container {
        width: 100%;
        max-width: 500px;
        margin: 0 auto;
        display: flex;
        flex-direction: column;
        gap: 1rem;
        padding: 1rem;
        background: var(--glass-bg);
        border: 1px solid var(--glass-border);
        border-radius: var(--border-radius);
        backdrop-filter: blur(10px);
      }

      .words {
        width: 100%;
        height: 50px;
        display: block;
        text-align: left;
        font-size: 1rem;
        padding: 0.75rem;
        border: 1px solid var(--glass-border);
        border-radius: var(--border-radius);
        background: var(--glass-bg);
        color: var(--text-color);
        transition: var(--transition);
      }

      .words:focus {
        outline: none;
        border-color: var(--accent-color);
        box-shadow: 0 0 0 2px rgba(0, 255, 136, 0.1);
      }

      .words::placeholder {
        color: rgba(255, 255, 255, 0.5);
      }

      .icons_div {
        display: flex;
        justify-content: center;
        gap: 1.5rem;
        padding: 0.5rem;
        margin-bottom: 1rem;
      }

      .icon {
        width: 45px;
        height: 45px;
        font-size: 1.2rem;
      }

      #modifiedText {
        margin-top: 0.5rem;
        font-size: 0.9rem;
        color: var(--text-color);
        opacity: 0.8;
      }

      .camera-preview {
        display: none;
        position: relative;
        width: 100%;
        max-width: 600px;
        margin: 0 auto;
      }

      #previewVideo {
        width: 100%;
        height: 100%;
        object-fit: contain;
        display: block;
      }

      .camera-controls {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        display: flex;
        justify-content: center;
        align-items: center;
        gap: 1rem;
        padding: 1rem;
      }

      .control-btn {
        width: 45px;
        height: 45px;
        font-size: 1.2rem;
        background: var(--glass-bg);
        border: 1px solid var(--glass-border);
        border-radius: var(--border-radius);
        backdrop-filter: blur(10px);
      }
    </style>
  </head>
  <body>
    <div class="main_container">
      <div id="animation_container">
        <img id="avatarImage" src="static/images/avatar.png" alt="Avatar" />
        <video id="wordAnimation" autoplay>
          <source id="animationSource" src="" type="video/mp4" />
          Your browser does not support the video tag.
        </video>
      </div>

      <div class="output-container">
        <div class="words" id="textInput" contenteditable="true" placeholder="Speak your mind...">Speak your mind...</div>
        <div class="icons_div">
          <div class="icon" id="micButton">
            <i class="fas fa-microphone"></i>
          </div>
          <div class="icon" id="cameraButton">
            <i class="fas fa-camera"></i>
          </div>
        </div>
        <div id="cameraPreview" class="camera-preview">
          <video id="previewVideo" autoplay playsinline></video>
          <canvas id="detectionCanvas" class="detection-canvas"></canvas>
          <div class="camera-controls">
            <div class="detection-status">No hand detected</div>
          </div>
        </div>
        <div id="modifiedText"></div>
      </div>
    </div>

    <script>
      let isRecording = false;
      let isRunning = false;
      let transcribedText = "";
      let finalWordsDict = {};

      let mediaRecorder;
      let audioChunks = [];
      let stream;

      const words = document.querySelector(".words");
      const micButton = document.getElementById("micButton");
      const cameraButton = document.getElementById("cameraButton");
      const modifiedText = document.getElementById("modifiedText");
      const wordAnimation = document.getElementById("wordAnimation");
      const animationSource = document.getElementById("animationSource");
      const avatarImage = document.getElementById("avatarImage");
      const textInput = document.getElementById("textInput");

      // Camera and Hand Detection functionality
      let cameraStream = null;
      let detectionCanvas = document.getElementById('detectionCanvas');
      let ctx = detectionCanvas.getContext('2d');
      let detectionStatus = document.querySelector('.detection-status');

      micButton.addEventListener("click", async () => {
        console.log("ðŸŽ™ï¸ Mic button clicked");

        if (isRecording) {
          micButton.querySelector('i').classList.remove('fa-stop');
          micButton.querySelector('i').classList.add('fa-microphone');
          micButton.style.background = '';
          await stopRecording();
          isRecording = false;
        } else {
          micButton.querySelector('i').classList.remove('fa-microphone');
          micButton.querySelector('i').classList.add('fa-stop');
          micButton.style.background = '#ff4444';
          await startRecording();
          isRecording = true;
        }
      });

      async function startCamera() {
        try {
          cameraStream = await navigator.mediaDevices.getUserMedia({ 
            video: { 
              width: { ideal: 1280 },
              height: { ideal: 720 },
              facingMode: "user"
            } 
          });
          previewVideo.srcObject = cameraStream;
          cameraPreview.style.display = 'block';
          
          // Set canvas size to match video
          previewVideo.onloadedmetadata = () => {
            detectionCanvas.width = previewVideo.videoWidth;
            detectionCanvas.height = previewVideo.videoHeight;
          };
          
          // Start hand detection
          console.log("Starting hand detection");
          cameraButton.querySelector('i').classList.remove('fa-camera');
          cameraButton.querySelector('i').classList.add('fa-stop');
          cameraButton.style.background = '#ff4444';
          const response = await fetch('/start', { method: 'POST' });
          const result = await response.json();
          console.log(result.status);
          isRunning = true;
          
          // Start processing frames
          processVideoFrame();
        } catch (err) {
          console.error('Error accessing camera:', err);
          alert('Could not access camera. Please ensure you have granted camera permissions.');
        }
      }

      async function stopCamera() {
        if (cameraStream) {
          cameraStream.getTracks().forEach(track => track.stop());
          previewVideo.srcObject = null;
          cameraPreview.style.display = 'none';
          
          // Stop hand detection
          console.log("Stopping hand detection");
          cameraButton.querySelector('i').classList.remove('fa-stop');
          cameraButton.querySelector('i').classList.add('fa-camera');
          cameraButton.style.background = '';
          const response = await fetch('/stop', { method: 'POST' });
          const result = await response.json();
          console.log(result.status);
          isRunning = false;
          
          // Clear canvas
          ctx.clearRect(0, 0, detectionCanvas.width, detectionCanvas.height);
        }
      }

      async function processVideoFrame() {
        if (!isRunning) return;
        
        try {
          // Draw the video frame to the canvas
          ctx.drawImage(previewVideo, 0, 0, detectionCanvas.width, detectionCanvas.height);
          
          // Get the frame data for processing
          const imageData = ctx.getImageData(0, 0, detectionCanvas.width, detectionCanvas.height);
          
          // Send frame to server for processing
          const response = await fetch('/process-frame', {
            method: 'POST',
            body: JSON.stringify({
              width: detectionCanvas.width,
              height: detectionCanvas.height,
              data: Array.from(imageData.data)
            }),
            headers: {
              'Content-Type': 'application/json'
            }
          });
          
          const result = await response.json();
          
          // Update detection status
          if (result.detected) {
            detectionStatus.textContent = `Detected: ${result.label}`;
            detectionStatus.style.color = '#00ff00';
            
            // Draw detection box
            ctx.strokeStyle = '#00ff00';
            ctx.lineWidth = 2;
            ctx.strokeRect(
              result.bbox.x,
              result.bbox.y,
              result.bbox.width,
              result.bbox.height
            );
          } else {
            detectionStatus.textContent = 'No hand detected';
            detectionStatus.style.color = '#ffffff';
          }
          
          // Continue processing frames
          requestAnimationFrame(processVideoFrame);
        } catch (err) {
          console.error('Error processing frame:', err);
          requestAnimationFrame(processVideoFrame);
        }
      }

      cameraButton.addEventListener('click', () => {
        if (!isRunning) {
          startCamera();
        } else {
          stopCamera();
        }
      });

      async function startRecording() {
        try {
          stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          
          mediaRecorder = new MediaRecorder(stream);
          audioChunks = [];

          mediaRecorder.ondataavailable = event => {
            console.log("ðŸŽ™ï¸ Audio chunk captured:", event.data);
            audioChunks.push(event.data);
          };
          
          mediaRecorder.onstop = async () => {
            console.log("ðŸ›‘ Recording stopped...");
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });

            const audioURL = URL.createObjectURL(audioBlob);
            const audio = new Audio(audioURL);

            const formData = new FormData();
            formData.append('audio', audioBlob, 'speech.webm');

            try {
              const response = await fetch('/speech-to-text', {
                method: 'POST',
                body: formData
              });
              const result = await response.json();
              const text = result.transcript;
              console.log("Transcript:", text);

              // Update the text input with the transcribed text
              textInput.textContent = text;
              processText(text);
            } catch (error) {
              console.error("Error processing speech:", error);
              textInput.textContent = "Error processing speech. Please try again.";
            }
          };

          mediaRecorder.start();
          console.log("Recording started...");
        } catch (error) {
          console.error("Error starting recording:", error);
          textInput.textContent = "Error accessing microphone. Please check permissions.";
        }
      }

      function stopRecording() {
        return new Promise((resolve) => {
          if (mediaRecorder && mediaRecorder.state === "recording") {
            console.log("Stopping mediaRecorder...");
            mediaRecorder.stop();
            
            setTimeout(() => {
              if (stream) {
                console.log("Stopping all audio tracks...");
                stream.getTracks().forEach(track => track.stop());
                stream = null;
              }
              resolve();
            }, 300);
          } else {
            console.log("MediaRecorder was not recording");
            if (stream) {
              console.log("Stopping all audio tracks anyway...");
              stream.getTracks().forEach(track => track.stop());
              stream = null;
            }
            resolve();
          }
        });
      }

      textInput.addEventListener("keydown", (e) => {
        if (e.key === "Enter") {
          e.preventDefault();
          const text = textInput.textContent.trim();
          console.log("Text to process:", text);
          if (text) {
            processText(text);
            textInput.textContent = ""; // Clear the input box
          }
        }
      });

      async function processText(text) {
        try {
          // Clear previous values
          finalWordsDict = {};
          transcribedText = "";

          console.log("Sending data:", text);
          const response = await fetch("/", {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
            },
            body: JSON.stringify({ text }),
          });

          if (!response.ok) {
            throw new Error("Network response was not ok.");
          }

          const result = await response.json();
          if (result.error) {
            throw new Error(result.error);
          }

          finalWordsDict = result.modified_text;
          modifiedText.textContent = `ISL: ${Object.values(finalWordsDict).join(" ")}`;
          console.log("Modified text:", finalWordsDict);

          // Start playing the animation for the words
          playAnimations(Object.values(finalWordsDict));
        } catch (error) {
          console.error("Error processing text:", error);
          modifiedText.textContent = `Error: ${error.message}`;
        }
      }

      function playAnimations(words) {
        console.log("Playing animation");
        let index = 0;

        function playNextWord() {
          if (index < words.length) {
            const word = words[index].toLowerCase();
            const videoPath = `static/${word}.mp4`;

            animationSource.src = videoPath;
            wordAnimation.style.display = "block"; // Show the video
            avatarImage.style.display = "none"; // Hide the avatar
            wordAnimation.load();
            wordAnimation.play();

            wordAnimation.onended = () => {
              index++;
              playNextWord();
            };
          } else {
            // Clear the video source when all animations are played
            animationSource.src = "";
            wordAnimation.style.display = "none"; // Hide the video
            avatarImage.style.display = "block"; // Show the avatar
            wordAnimation.load();

            // Optionally reload the page or reset state after animations
            setTimeout(() => window.location.reload(), 100); // Delay reload to allow last video to end
          }
        }

        playNextWord();
      }
    </script>
  </body>
</html>